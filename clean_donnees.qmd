---
title: "clean_donnees"
format: html
editor: visual
---

## 1. Rassembler les deux tableaux de données

a)  récupérer les tableaux de données brute.

```{r}
#charger le chemin d'accès : à adapter à votre ordinateur 
setwd("~/Desktop/M2/projet biodiversite/oiseaux_bagnas")

#charger les données brutes: 2 tableaux
raw_data<- read_excel("~/Desktop/M2/projet biodiversite/oiseaux_bagnas/data/raw/synthese_observations_2025-09-09T13_30_50.994Z.xlsx")

raw_data_2 <- read_delim(
  "~/Desktop/M2/projet biodiversite/oiseaux_bagnas/data/raw/synthese_observations_2025-11-24T07_38_00.302Z (2).csv",
  delim = ";",
  locale = locale(encoding = "Latin1", decimal_mark = ".")
)

```

Nous conservons uniquement les colonnes pertinentes pour la suite de l'analyse, en supprimant les colonnes vides ainsi que celles dont l'information est redondante, notamment les noms latins.

```{r}

process_data_1= raw_data %>%
  select(id_synthese,date_debut,date_fin,heure_debut,heure_fin,
         nom_vernaculaire,nombre_min,observateurs,determinateur,x_centroid_4326,
         y_centroid_4326,nom_lieu,champs_additionnels)

process_data_2 <- raw_data_2 %>%
  select(id_synthese, date_debut, date_fin, heure_debut, heure_fin,
         nom_vernaculaire, nombre_min, observateurs, determinateur,
         x_centroid_4326, y_centroid_4326,
         nom_lieu, champs_additionnels)

# On garde uniquement l'heure (HH:MM:SS) dans heure_debut / heure_fin
# car le fichier original contenait une date + une heure
process_data_1 <- process_data_1 %>%
  mutate(
    heure_debut = format(heure_debut, "%H:%M:%S"),
    heure_fin   = format(heure_fin,   "%H:%M:%S")
  )

# mettre en format date les dates de debut et de fin 

process_data_1 <- process_data_1 %>%
  mutate( date_debut = as.Date(date_debut, format = "%d/%m/%Y"),
          date_fin = as.Date(date_fin, format = "%d/%m/%Y") )



process_data_2 <- process_data_2 %>%
  mutate( date_debut = as.Date(date_debut, format = "%d/%m/%Y"),
          date_fin = as.Date(date_fin, format = "%d/%m/%Y") )

#correction des formats de certaines colonnes
process_data_2 <- process_data_2 %>%
  mutate(
    x_centroid_4326 = as.character(x_centroid_4326),
    y_centroid_4326 = as.character(y_centroid_4326)
  )

process_data_1<- process_data_1 %>%
  mutate(
    x_centroid_4326 = round(as.numeric(x_centroid_4326), 6),
    y_centroid_4326 = round(as.numeric(y_centroid_4326), 6)
  )

process_data_2 <- process_data_2 %>%
  mutate(
    x_centroid_4326 = round(as.numeric(x_centroid_4326), 6),
    y_centroid_4326 = round(as.numeric(y_centroid_4326), 6)
  )
# Le fichier brut est en format "dd/mm/YYYY"
# On convertit proprement en Date (format standard YYYY-MM-DD)


process_data_2 <- process_data_2 %>%
  mutate(
    heure_debut = as.character(heure_debut),
    heure_fin   = as.character(heure_fin)
  )

# La ligne 132 de process_data_2 avait un NA
# On remplace par la valeur correspondante dans process_data_1 (ligne 720)
process_data_2$champs_additionnels[ process_data_2$id_synthese == 124571 ] <- 
  process_data_1$champs_additionnels[720]

#création du tableau final avec les 3 espèces et les colonnes dans le bon format. C'est ce tableau qui est par la suite utilisé. 
process_data = process_data_2

write_csv(process_data, "~/Desktop/M2/projet biodiversite/oiseaux_bagnas/data/pro/process_data.csv")

```

## 2. Créer le tableau de données utilisé dans les analyses sur le protocole

```{r}
#floor date permet de récuperer l'année et de créer une nouvelle colonne uniquement avec l'année
process_data$annee = year(floor_date(process_data$date_debut, "year"))

#on filtre pour enlever toutes les données avant 2014 (le début des protocoles)
# on filtre pour garder uniquement les données protocolées : on garde les lieux protocolés "ButorTalèveBlongios de 1 à 9 ; on garde uniquement les données rensignées comme protocolés SuiviButor|BlongiosTalève
process_protocole = process_data  %>%
  filter(annee>= 2014) %>%
  filter (nom_lieu  %in% paste0 ("ButorTalèveBlongios-", 1 : 9)) %>%
  filter( champs_additionnels== "{'RELV_NOM': 'SuiviButor'}" |
          champs_additionnels== "{'RELV_NOM': 'SuiviBlongiosTalève'}")


#écrire le nouveau csv des données >2014 protocolées 
write_csv(process_protocole, "~/Desktop/M2/projet biodiversite/oiseaux_bagnas/data/pro/process_protocole.csv")


```

##3. Les données environnementales

```{r}
#chemin pour aller chercher les données environnementales, à changer selon l'ordinateur
setwd("~/Desktop/M2/projet biodiversite/oiseaux_bagnas/data_enviro")

#récuperer les csv bruts pour chaque année 
file_2013 <- read_delim("2013.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)

file_2014 <- read_delim("2014.csv", delim = ";", 
                       escape_double = FALSE, trim_ws = TRUE, 
                       skip = 4)
file_2015 <- read_delim("2015.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)
file_2016 <- read_delim("2016.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)
file_2017 <- read_delim("2017.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)
file_2018 <- read_delim("2018.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)
file_2019 <- read_delim("2019.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)
file_2020 <- read_delim("2020.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)
file_2021 <- read_delim("2021.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)
file_2022 <- read_delim("2022.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)
file_2023 <- read_delim("2023.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)
file_2024 <- read_delim("2024.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)
file_2025 <- read_delim("2025.csv", delim = ";", 
                        escape_double = FALSE, trim_ws = TRUE, 
                        skip = 4)

#enlever la première ligne qui donne les unités des colonnes (toujours présent dans les données brutes si besoin de les retrouver )
file_2013 <- file_2013[-1, ]
file_2014 <- file_2014[-1, ]
file_2015 <- file_2015[-1, ]
file_2016 <- file_2016[-1, ]
file_2017 <- file_2017[-1, ]
file_2018 <- file_2018[-1, ]
file_2019 <- file_2019[-1, ]
file_2020 <- file_2020[-1, ]
file_2021 <- file_2021[-1, ]
file_2022 <- file_2022[-1, ]
file_2023 <- file_2023[-1, ]
file_2024 <- file_2024[-1, ]
file_2025 <- file_2025[-1, ]

#on crée un data frame avec tous les fichiers 
data_environnement <- bind_rows(file_2013, file_2014, file_2015, file_2016, file_2017, file_2018, file_2019, file_2020, file_2021, file_2022, file_2023, file_2024, file_2025)

#écrire le CVS avec toutes les données 
write_csv(data_environnement, "~/Desktop/M2/projet biodiversite/oiseaux_bagnas/data_enviro/raw_environnement.csv")

#tri et clean des données environnementales : les données sont toutes les 20min depuis 2013.
data_environnement2=data_environnement

#mettre la date en bon format
data_environnement2$dh_utc= as.POSIXct(data_environnement2$dh_utc, format =c("%Y-%m-%d %H:%M:%S"), tz="UTC")

data_environnement2$date <- as.Date(data_environnement2$dh_utc)


data_environnement2_clean <- data_environnement2 %>%
  mutate(Date = as.Date(date)) %>%
  mutate(across(!c(Date,dh_utc), ~ suppressWarnings(as.numeric(.x))))


environnement_daily <- data_environnement2_clean %>%
  group_by(Date) %>%
  summarise(across(where(is.numeric),
                   ~ mean(.x, na.rm = TRUE)),
            .groups = "drop")
summary(environnement_daily)


#écriture du csv propre qui sera utilisé par la suite : 1 donnée par jour (moyenne de toutes les variables qui étaient toutes les 20min) -> nommé environnement_daily
write_csv(environnement_daily, "~/Desktop/M2/projet biodiversite/oiseaux_bagnas/data_enviro/environnement_daily.csv")




```

```{r}
##### création des lignes pour les jours manquants du tableau environnement_daily

# étape 1 création d'un tableau de 2013 à 2025 avec une variable jour julian

date_debut <- as.Date("2013-01-01")
date_fin   <- as.Date("2025-12-31")

toutes_dates <- seq(from = date_debut, to = date_fin, by = "day")

données_2013_2025 <- data.frame(
  Date = toutes_dates)

données_2013_2025$julian = yday(données_2013_2025$Date)

View(données_2013_2025)

# étape 2 on va forcer le rajout des lignes avec un full.join qui permet de rajouter toutes les lignesdu tableau 2 au premier tableau meme si les lignes n'ont pas de jointures

environnement_daily <- environnement_daily %>%
  full_join(
    données_2013_2025 %>% select(Date, julian),
    by = "Date"
  )

# Etape 3 verification du jeu de données

# Nombre de jours par année
environnement_daily %>%
  mutate(Annee = year(Date)) %>%
  count(Annee)

# les lignes manquantes si il y'en a
résumé_jours_NA = environnement_daily %>%
  filter(is.na(temperature)) %>%        
  mutate(Annee = year(Date)) %>%        
  group_by(Annee) %>%                   
  summarise(
    nb_lignes = n(),                     
    nb_jours_uniques = n_distinct(Date)  
  )

```

### 3.2 Rajout des moyennes glissantes

```{r}
# On calcule la variable temperatuere et pluie moyenne glissante sur 31 jours 

environnement_daily <- environnement_daily %>%
  arrange(Date) %>%
  mutate(
    temp_moy_glissante_31j = slide_dbl(
      temperature,
      mean,
      .before = 31,
      .after = 0,
      .complete = TRUE,
      na.rm = TRUE
    )
  )

environnement_daily <- environnement_daily %>%
  arrange(Date) %>%
  mutate(
    temp_moy_glissante_7j = slide_dbl(
      temperature,
      mean,
      .before = 7,
      .after = 0,
      .complete = TRUE,
      na.rm = TRUE
    )
  )

environnement_daily <- environnement_daily %>%
  arrange(Date) %>%
  mutate(
    pluie_moy_glissante_31j = slide_dbl(
      pluie_1h,
      mean,
      .before = 31,
      .after = 0,
      .complete = TRUE,
      na.rm = TRUE
    )
  )
environnement_daily <- environnement_daily %>%
  arrange(Date) %>%
  mutate(
    pluie_moy_glissante_7j = slide_dbl(
      pluie_1h,
      mean,
      .before = 7,
      .after = 0,
      .complete = TRUE,
      na.rm = TRUE
    )
  )
```

Fusion des tableaux

```{r}
process_protocole = process_protocole %>%
  inner_join( environnement_daily,by = c("date_debut"= "Date") )
```

Rajout des variables hydro dans le process_protocole et environnement_daily

```{r}
DataHydroBagnas<- DataHydroBagnas%>%

 mutate( date = as.Date(Jour-1 , origin = paste0(Annee, "-01-01")) )

environnement_daily = environnement_daily %>%
  inner_join( DataHydroBagnas,by = c("Date"= "date") )%>%
  select(-Annee, -Jour)

process_protocole <- process_protocole %>%
  inner_join(DataHydroBagnas, by = c("date_debut" = "date")) %>%
  select(-Annee, -Jour)

write_csv(environnement_daily, "data/environnement_daily.csv")

write_csv(process_protocole, "data/process_protocole.csv")
```

write_csv(environnement_daily, "data/environnement_daily.csv")

write_csv(process_protocole, "data/process_protocole.csv")

##4. Les données hydro

```{r}

### Importe les packages
library(ggplot2)
library(dplyr)
library(lubridate)
library(purrr)

### Importation des données brutes
HydrologicData <- read.csv("data/raw/DataHydro.csv", sep = ";")

### On sélectionne les colonnes qui nous interessent dans le data frame hydro et on remet les données sous le bon format et les données après 2013
HydrologicDataGrandBagnas <- HydrologicData %>%
  select(Station, Date.Releve, Heure, Salinite, Temperature, Niveau.Ngf, Niveau.Relatif)%>%
  mutate(Profondeur = (Niveau.Ngf+0.27),
         Date.Releve = as.Date(Date.Releve, format = "%d/%m/%Y"),
         Annee = as.integer(format(Date.Releve, "%Y")),
         Mois = format(Date.Releve, "%m"),
         Jour = yday(Date.Releve))%>%
  filter(Station == "Etangs du Grand Bagnas - TB5 centre",
         Annee > 2013)

### Calcule la profondeur et l'altitude moyenne (de l'eau) mensuelle
Hydro_moyenne <- HydrologicDataGrandBagnas %>%
  group_by(Annee, Mois) %>%
  summarise(
    ProfondeurMoyenne = mean(Profondeur, na.rm = TRUE),
    AltitudeMoyenne = mean(Niveau.Ngf, na.rm = TRUE),
    .groups = "drop")

### Code une variable Assec (mois par mois) et AssecT (niveau le plus extreme de l'année) 
HydrologicDataGrandBagnas <- HydrologicDataGrandBagnas %>%
  mutate(
    Assec = case_when(
      is.na(Profondeur) ~ "total",
      Profondeur < 0.2  ~ "partiel",
      TRUE                     ~ "non"),
    Assec_score = case_when(
      Assec == "non"     ~ 1,
      Assec == "partiel" ~ 2,
      Assec == "total"   ~ 3)) %>%
  group_by(Annee) %>%
  mutate(
    AssecT = case_when(
      max(Assec_score, na.rm = TRUE) == 3 ~ "total",
      max(Assec_score, na.rm = TRUE) == 2 ~ "partiel",
      TRUE                                ~ "non")) %>%
  ungroup() %>%
  select(-Assec_score)

### Crée une variable AssecT_1 (AssecT de l'année précédente)
Assec_annuel <- HydrologicDataGrandBagnas %>%
  distinct(Annee, AssecT) %>%
  bind_rows(tibble(Annee = 2014, AssecT = "non")) %>%
  filter(Annee != 2026) %>%                             
  arrange(Annee) %>%
  mutate(AssecT_1 = lag(AssecT),
         AssecT_1 = if_else(Annee == 2014, "non", AssecT_1))%>%
  group_by(Annee) %>%
  slice(1) %>%   
  ungroup()

### Ajoute la variable AssecT_1 au tableau HydrologicDataGrandBagnas
HydrologicDataGrandBagnas <- HydrologicDataGrandBagnas %>%
  left_join(
    Assec_annuel %>% select(Annee, AssecT_1),
    by = "Annee")

### Conserve que les bonnes variables 
HydrologicDataGrandBagnas <- HydrologicDataGrandBagnas[,c(8,9,10,11,14)]

### Remplace les valeurs NA de Profondeur par 0
HydrologicDataGrandBagnas <- HydrologicDataGrandBagnas %>%
  mutate(Profondeur = if_else(is.na(Profondeur), 0, Profondeur))

### Convertit la variable Mois en numérique  
HydrologicDataGrandBagnas$Mois <- as.numeric(as.character(HydrologicDataGrandBagnas$Mois))

### Graphique de la profondeur moyenne mensuelle par année
ggplot(HydrologicDataGrandBagnas, aes(x = Mois, y = Profondeur)) +
  geom_line() +
  geom_point() +
  facet_wrap(~ Annee, ncol = 3) +
  scale_x_continuous(breaks = 1:12) +
  theme_bw()

## INTERPOLATION LINÉAIRE DE LA PROFONDEUR JOURNALIÈRE

### On crée une fonction qui génère un data frame avec les jours de l'année
jours_par_annee <- function(df) {
  data.frame(Jour = 1:365)}

### On applique la fonction à chaque année pour avoir un tableau avec tous les jours de chaque année
DataInterpolationProfondeur <- HydrologicDataGrandBagnas %>%
  group_by(Annee) %>%
  group_modify(~ {    interp <- approx(
      x = .x$Jour,
      y = .x$Profondeur,
      xout = 1:365,   
      rule = 2         )
    tibble(
      Jour = interp$x,
      Profondeur = interp$y)}) %>% ungroup()

### Ajoute les colonnes Date, Mois au tableau DataInterpolationProfondeur
AssecT_1_annee <- HydrologicDataGrandBagnas %>%
  select(Annee, AssecT_1) %>%
  distinct()

### Crée la colonne Date
HydrologicDataGrandBagnas <- DataInterpolationProfondeur %>%
  left_join(AssecT_1_annee, by = "Annee")

### Enregistre le tableau final dans le fichier processed
write.csv(HydrologicDataGrandBagnas, file = "data/pro/DataHydroBagnas.csv", row.names = FALSE)
```

## 5. Analyses exploratoires

#### A. les observateurs Script d'Émile

#### B. cartographie des sites protocoles avec la taille des points qui montre l'abondance par site (de 2014 à 2025 confondu) pour chaque espèce

```{r}
#chargement des library (plus que necessaire : il faut que j'en enlève)
library(leaflet)
library(sf)
library(RColorBrewer) 
library(dplyr)
library(readr)
library(tidyverse) 
library(lubridate) 
library(readxl) 
library(ggplot2) 
library(dplyr)
library(gridExtra)
library(readr)
library(knitr)
library(lme4)
```

Cartographie des sites d'observation/écoute des 3 espèces. Tous types de données mélangées (protocole et hors protocole) depuis 2014

```{r}

#1 : tous les sites 

#2 : les sites du protocole :
#on va chercher le csv process_protocole dans l'ordinateur
process_protocole <- read_csv("~/Desktop/M2/projet biodiversite/oiseaux_bagnas/data/pro/process_protocole.csv")

#préparer les coordonnées pour que R comprenne 
sites_protocole <- st_as_sf(process_protocole, coords = c("x_centroid_4326", "y_centroid_4326"), crs = 4326)

#le package leaflet permet de projeter des coordonnées sur la carte du monde
leaflet() %>%
  addTiles() %>%     # fond OSM

  addCircleMarkers(
    data =sites_protocole, 
    radius = 5,
    color = "red",
    fillOpacity = 0.9,
    popup = ~nom_lieu  #quand on appuie sur les point de la carte le nom des sites du protocole apparraissent 
  ) %>%
  setView(lng = 3.3, lat = 43.6, zoom = 9)

```

d)  talève

```{r}


```
