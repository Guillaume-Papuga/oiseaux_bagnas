

```{r}
library(tidyverse)
library(lubridate) 
library(readxl)
library(lubridate) 
library(ggplot2) 
library(sf)


getwd()

raw_data<- read.csv("process_data.csv")

#clean 

process_data<- raw_data %>%
  select(id_synthese,date_debut,date_fin,heure_debut,heure_fin,
         nom_vernaculaire,nombre_min,observateurs,determinateur,x_centroid_4326,
         y_centroid_4326,nom_lieu,champs_additionnels)

write.csv(process_data,
          file = "C:/Users/emile/Documents/oiseaux_bagnas/data/pro/process_data.csv",
          row.names = FALSE)
```


```{r}
library(ggplot2)
library(dplyr)
library(forcats)
library(stringr)

# --- 0) Diagnostic : afficher un aperçu de process_data ---
cat("Aperçu de process_data (5 premières lignes) :\n")
print(utils::head(process_data, 5))
cat("\nStructure de process_data :\n")
print(str(process_data))

library(stringi)
library(stringr)
library(dplyr)

process_data <- process_data %>%
  mutate(observateurs = as.character(observateurs)) %>%
  
  # Séparer provisoirement sur "/"
  mutate(observateurs = sapply(observateurs, function(x) {
    
    # si NA → NA
    if (is.na(x)) return(NA)
    
    # séparer en plusieurs observateurs mais sans éclater les lignes
    noms <- strsplit(x, "/")[[1]]
    
    # nettoyage individuel
    noms_clean <- noms %>%
      trimws() %>%                                # enlever espaces
      tolower() %>%                               # minuscules
      stringi::stri_trans_general("Latin-ASCII") %>%  # enlever accents
      sapply(function(y) {
        mots <- unlist(strsplit(y, " +"))         # séparer mots
        mots <- sort(mots)                        # trier mots
        paste(mots, collapse = " ")               # reconstruire
      })
    
    # remettre les noms ensemble avec "/"
    paste(noms_clean, collapse = " / ")
  }))





# --- 1) Re-créer data_filtered au cas où (exclusion ADENA, insensible à la casse et aux espaces) ---
data_filtered <- process_data %>%
  # s'assurer que la colonne existe et est en caractère
  mutate(observateurs = as.character(observateurs)) %>%
  # nettoyer espaces début/fin et remplacer NA par "NA_obs" si besoin (optionnel)
  mutate(observateurs = str_trim(observateurs)) %>%
  # exclusion insensible à la casse de "ADENA" (gère "Adena", " ADENA ", etc.)
  filter(!is.na(observateurs) & !(str_to_upper(observateurs) == "ADENA"))

cat("\nVérification data_filtered (5 premières lignes) :\n")
print(utils::head(data_filtered, 5))
cat("\nNombre de lignes après filtre :", nrow(data_filtered), "\n")

# --- 2) Agrégation : somme de nombre_min par observateur ---
data_summarized <- data_filtered %>%
  # s'assurer que nombre_min est numérique
  mutate(nombre_min = as.numeric(nombre_min)) %>%
  group_by(observateurs) %>%
  summarise(
    total_min = sum(nombre_min, na.rm = TRUE),
    n_rows = n(),
    .groups = "drop"
  )

cat("\nTable agrégée (top 20) :\n")
print(utils::head(arrange(data_summarized, desc(total_min)), 20))

# Vérification d'éventuels problèmes
if (nrow(data_summarized) == 0) {
  stop("data_summarized est vide — vérifie que data_filtered contient des lignes et que la colonne nombre_min est numérique.")
}
if (all(is.na(data_summarized$total_min))) {
  stop("Toutes les sommes sont NA — vérifie la colonne nombre_min (valeurs non numériques).")
}

# --- 3) Réordonner les observateurs pour un affichage clair (optionnel) ---
data_summarized <- data_summarized %>%
  arrange(desc(total_min)) %>%
  mutate(observateurs = factor(observateurs, levels = observateurs))

# --- 4) Tracer le barplot avec geom_col() et valeurs au-dessus des barres ---
p <- ggplot(data_summarized, aes(x = observateurs, y = total_min)) +
  geom_col() +                           # geom_col() = geom_bar(stat="identity")
  geom_text(aes(label = round(total_min, 1)), 
            vjust = -0.3, size = 3) +    # afficher la valeur au-dessus
  labs(
    title = "Nombre total (nombre_min) par observateur\n(sans ADENA)",
    x = "Observateur",
    y = "Total nombre_min"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

print(p)











library(dplyr)
library(tidyr)
library(stringr)
library(stringi)

# 1) Nettoyage et séparation des observateurs
data_clean <- process_data %>%
  mutate(observateurs = as.character(observateurs)) %>%
  # Exclusion ADENA insensible à la casse
  filter(!is.na(observateurs) & str_to_upper(str_trim(observateurs)) != "ADENA") %>%
  # Séparer les observateurs sur "/"
  separate_rows(observateurs, sep = "/") %>%
  mutate(
    observateurs = str_trim(observateurs),                     # enlever espaces
    observateurs = tolower(observateurs),                     # minuscules
    observateurs = stringi::stri_trans_general(observateurs, "Latin-ASCII"), # enlever accents
    # trier les mots dans le nom
    observateurs = sapply(observateurs, function(x) {
      mots <- unlist(strsplit(x, " +"))
      paste(sort(mots), collapse = " ")
    })
  )

# 2) Agrégation
data_summarized <- data_clean %>%
  mutate(nombre_min = as.numeric(nombre_min)) %>%
  group_by(observateurs) %>%
  summarise(total_min = sum(nombre_min, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(total_min)) %>%
  mutate(observateurs = factor(observateurs, levels = observateurs))

# 3) Barplot
library(ggplot2)

ggplot(data_summarized, aes(x = observateurs, y = total_min)) +
  geom_col() +
  geom_text(aes(label = total_min), vjust = -0.3, size = 3) +
  labs(
    title = "Nombre total (nombre_min) par observateur\n(sans ADENA)",
    x = "Observateur",
    y = "Total nombre_min"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))








```

```{r}
library(ggplot2)
library(dplyr)
library(lubridate)

# Vérifie que la colonne "date_debut" est bien au format Date
process_data <- process_data %>%
  mutate(date_debut = as.Date(date_debut))  

#  enlever "ADENA" 
process_data <- process_data %>%
  filter(observateurs != "")

#  trier les observateurs par fréquence
process_data <- process_data %>%
  mutate(observateurs = forcats::fct_infreq(observateurs))

# --- Graphe de présence ---
ggplot(process_data, aes(x = date_debut, y = observateurs)) +
  geom_point(alpha = 0.7, color = "steelblue", size = 3) +
  labs(
    title = "Présence des observateurs dans le temps",
    x = "Date de début", 
    y = "Observateurs"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```


```{r}
library(stringi)
library(stringr)
library(dplyr)

process_data <- process_data %>%
  mutate(observateurs = as.character(observateurs)) %>%
  
  # 1) mettre en minuscules
  mutate(observateurs = str_to_lower(observateurs)) %>%
  
  # 2) enlever accents
  mutate(observateurs = stringi::stri_trans_general(observateurs, "Latin-ASCII")) %>%
  
  # 3) enlever ponctuation + espaces multiples
  mutate(observateurs = str_replace_all(observateurs, "[^a-z ]", " ")) %>%
  mutate(observateurs = str_squish(observateurs)) %>%
  
  # 4) réordonner les mots
  mutate(observateurs = sapply(strsplit(observateurs, " "), function(x) {
    paste(sort(x), collapse = " ")
  }))

```
 
 
```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(stringi)

# 1) Séparation et nettoyage des observateurs 
data_clean <- process_data %>%
  mutate(observateurs = as.character(observateurs)) %>%
  filter(!is.na(observateurs) & str_to_upper(str_trim(observateurs)) != "ADENA") %>%
  separate_rows(observateurs, sep = "/") %>%
  mutate(
    observateurs = str_trim(observateurs),
    observateurs = tolower(observateurs),
    observateurs = stringi::stri_trans_general(observateurs, "Latin-ASCII"),
    observateurs = sapply(observateurs, function(x) {
      mots <- unlist(strsplit(x, " +"))
      paste(sort(mots), collapse = " ")
    })
  )

# 2) Calcul du nombre d'observations par observateur
observations_par_obs <- data_clean %>%
  group_by(observateurs) %>%
  summarise(
    nb_observations = n(),
    total_min = sum(as.numeric(nombre_min), na.rm = TRUE),
    moyenne_par_obs = mean(as.numeric(nombre_min), na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(desc(nb_observations))

# 3) Affichage
print(observations_par_obs)

```

```{r}
---- glm avec effets aléatoires---- 
library(dplyr)
library(tidyr)
library(lubridate)
library(dplyr)
library(lubridate)
library(ggplot2)
library(readr)


process_data <- read.csv("process_protocole.csv")

#---- creer colonne presence ----
process_data <- process_data %>%
  mutate(presence = ifelse(nombre_min > 0, 1, 0))

#---- garder que taleve ---- 

process_data <- process_data %>%
  filter(nom_vernaculaire=="Talève sultane, Poule sultane, Porphyrion bleu")

#---- jours julien ----
process_data <- process_data %>%
  mutate(
    date_debut = as.Date(date_debut),       # convertir en Date
    annee = year(floor_date(date_debut, "year")),
    j_julien = yday(date_debut)
  ) %>%
  filter(annee > 2013)

#---- ajout colonne mois ----

process_data <- process_data %>%
  mutate(mois = factor(month(date_debut, label = TRUE, abbr = FALSE),
                       ordered = FALSE))


modele_mois <- glm(presence ~ mois,
                   data = process_data,
                   family = binomial)

summary(modele_mois)


#----  presence ~ temps ----
modele_jj <- glm(presence ~ j_julien,
              data = process_data,
              family = binomial)
summary(modele_jj)

#---- modele jour effet aleatoire annee+site ----
library(lme4)
modele_mixed <- glmer(
  presence ~ j_julien + (1 | annee)+ (1 | nom_lieu),   
  data = process_data,
  family = binomial
)
modele_mixed

#---- modele annee effet aleatoire jour ----
library(lme4)
modele_mixed <- glmer(
  presence ~ annee + (1 | j_julien),   
  data = process_data,
  family = binomial
)
modele_mixed

#---- par station ---- 
modele_s <- glm(presence ~ nom_lieu + j_julien,
              data = process_data,
              family = binomial)
summary(modele_s)

#---- modele nul ----

modele_nul <- glmer(
  presence ~ 1 + (1 | annee) + (1 | nom_lieu),
  data = process_data,
  family = binomial
)

anova(modele_nul, modele_mixed, test = "Chisq")























#========================
# LIBRAIRIES
#========================
library(dplyr)
library(lubridate)

#========================
# DONNEES
#========================
process_data <- read.csv("process_protocole.csv")

#========================
# PREPARATION
#========================
process_data <- process_data %>%
  mutate(
    presence = ifelse(nombre_min > 0, 1, 0),
    date_debut = as.Date(date_debut),
    annee = factor(year(date_debut)),
    j_julien = yday(date_debut),
    j_julien2 = j_julien^2,
    mois = factor(month(date_debut, label = TRUE, abbr = FALSE)),
    nom_lieu = factor(nom_lieu)
  ) %>%
  filter(
    nom_vernaculaire == "Talève sultane, Poule sultane, Porphyrion bleu",
    as.numeric(as.character(annee)) > 2013
  )

#========================
# MODELES CANDIDATS
#========================

# Modèle nul
m0 <- glm(presence ~ 1,
          data = process_data,
          family = binomial)

# Effet DATE (toujours j_julien + j_julien2)
m_date <- glm(presence ~ j_julien + j_julien2,
              data = process_data,
              family = binomial)

# Effet SITE
m_site <- glm(presence ~ nom_lieu,
              data = process_data,
              family = binomial)

# Effet ANNEE
m_annee <- glm(presence ~ annee,
               data = process_data,
               family = binomial)

# DATE + SITE
m_date_site <- glm(presence ~ j_julien + j_julien2 + nom_lieu,
                   data = process_data,
                   family = binomial)

# DATE + ANNEE
m_date_annee <- glm(presence ~ j_julien + j_julien2 + annee,
                    data = process_data,
                    family = binomial)

# SITE + ANNEE
m_site_annee <- glm(presence ~ nom_lieu + annee,
                    data = process_data,
                    family = binomial)

# DATE + SITE + ANNEE (modèle complet)
m_full <- glm(presence ~ j_julien + j_julien2 + nom_lieu + annee,
              data = process_data,
              family = binomial)

#========================
# COMPARAISON AIC
#========================
aic_tab <- AIC(
  m0,
  m_date,
  m_site,
  m_annee,
  m_date_site,
  m_date_annee,
  m_site_annee,
  m_full
)

print(aic_tab)

#========================
# MEILLEUR MODELE
#========================
best_model <- list(
  m0,
  m_date,
  m_site,
  m_annee,
  m_date_site,
  m_date_annee,
  m_site_annee,
  m_full
)[[which.min(aic_tab$AIC)]]

summary(best_model)

```


```{r}
#========================
# LIBRAIRIES
#========================
library(dplyr)
library(lubridate)
library(ggplot2)
library(lme4)

#========================
# DONNEES
#========================
process_data <- read.csv("process_protocole.csv")

#========================
# PREPARATION  # garder uniquement les lignes protocolées de talève
#========================
process_data <- process_data %>%
  filter(
    grepl("SuiviBlongiosTalève", champs_additionnels),
    nom_vernaculaire == "Talève sultane, Poule sultane, Porphyrion bleu"
  ) %>%
  mutate(
    presence   = ifelse(nombre_min > 0, 1, 0),
    date_debut = as.Date(date_debut),
    annee      = factor(lubridate::year(date_debut)),  # année en facteur
    j_julien   = lubridate::yday(date_debut),
    j_julien2  = j_julien^2,
    nom_lieu   = factor(nom_lieu)
  )


# ---- MODELE GLM ----
modele_phenologie <- glm(
  presence ~ j_julien + j_julien2 + annee,
  data = process_data,
  family = binomial
)

# ---- GRILLE DE PREDICTION (PAR ANNEE) ----
newdat <- process_data %>%
  group_by(annee) %>%
  summarise(
    j_julien = list(seq(min(j_julien), max(j_julien), by = 1)),
    .groups = "drop"
  ) %>%
  unnest(j_julien) %>%
  mutate(j_julien2 = j_julien^2)

# ---- PREDICTION ----
newdat$prob_detect <- predict(
  modele_phenologie,
  newdata = newdat,
  type = "response"
)

# ---- GRAPHE ----
ggplot(newdat, aes(x = j_julien, y = prob_detect, color = annee)) +
  geom_line(linewidth = 1) +
  labs(
    x = "Jour julien",
    y = "Probabilité de détection",
    color = "Année"
  ) +
  theme_minimal()



```


```{r}



m_glm <- glm(
  presence ~ j_julien + annee + nom_lieu,
  data = process_data,
  family = binomial
)

m_step <- step(
  m_glm,
  direction = "both",
  trace = TRUE
)

summary(m_step)




#---- occupancy ----
# Modèle d'occupancy nul : juste l'intercept
library(unmarked)

# Créer un objet unmarkedFrame pour les données d'occurrence
umf <- unmarkedFrameOccu(y = y_matrix, siteCovs = site_data, obsCovs = obs_data)

# Modèle d'occupancy nul
modele_nul <- occu(~1 ~1, data = umf)  # ~1 pour détection, ~1 pour occupancy
summary(modele_nul)



```






























